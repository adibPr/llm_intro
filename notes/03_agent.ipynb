{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5441bbb4-4041-4e13-9075-cc2d49c95fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/D/miniconda/envs/llm_intro/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import Optional, Any\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import numpy as np\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06787021-2c43-43d0-8c3c-ed0612e29494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure GOOGLE_API_KEY (or any other llm provider, must exactly the same)\n",
    "_ = load_dotenv(find_dotenv())\n",
    "# or put it into variable and pass it to llm model \n",
    "# google_api_key = os.getenv('GOOGLE_API_KEY') # pass this to the model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc08502-7b31-489b-b185-da27916771ba",
   "metadata": {},
   "source": [
    "# Agent Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1147b6-816b-4158-bc43-1bae92684707",
   "metadata": {},
   "source": [
    "![](../media/agent_tools.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d849e840-2639-416d-b645-5182176c59e8",
   "metadata": {},
   "source": [
    "What is an AI Agent? \n",
    "An AI agent is a program that uses a language model to understand a task and decide the best way to complete it using available tools autonomously.\n",
    "A key idea in AI agents is the set of **Tools** (functions) they can use to get the job done. \n",
    "For each request, the AI plans the best approach, deciding what steps and tools are needed and in what order to complete the task.\n",
    "\n",
    "For this example, we will create an Agent that could get the weather from external API, either by specify the location/city or by trying to use current location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d9852c4b-5670-4e5f-8535-ad7c99a13ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "agent that we use as example:\n",
    "    1. get weather\n",
    "    2. get location (dummy, returning random between Jakarta, Seoul, Tokyo)\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "import zoneinfo as zi\n",
    "import requests\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.tools import Tool, tool, StructuredTool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Type, Optional\n",
    "import random\n",
    "\n",
    "class Location(BaseModel):\n",
    "    location: str = Field(description='Location to find weather')\n",
    "    \n",
    "@tool\n",
    "def get_weather(location: Optional[str]='Jakarta') -> str:\n",
    "    \"\"\"Get the weather via API in a location (provided, Jakarta as default).\n",
    "    A tool designed to gather accurate information on weather around the globe. \n",
    "    Useful for when you need to answer questions about the weather. \n",
    "    Input should be the location.\n",
    "    \"\"\"\n",
    "    WEATHERAPI_API_KEY='8a6c94f591c4401c9e8152836251301'\n",
    "    res = requests.get(f'https://api.weatherapi.com/v1/current.json?key=8a6c94f591c4401c9e8152836251301&q={location}&aqi=no')\n",
    "    return \"For {} temperature: {:.2F} and weather: {}\".format(\n",
    "        location,\n",
    "        res.json()['current']['temp_c'],\n",
    "        res.json()['current']['condition']['text']\n",
    "        )\n",
    "@tool\n",
    "def get_current_location() -> str:\n",
    "    \"\"\"\n",
    "    Get the current location of a user (approxmate).\n",
    "    Input: None\n",
    "    Output: City name \n",
    "    \"\"\"\n",
    "\n",
    "    random_city = ['Jakarta', 'Seoul', 'Tokyo', 'Singapore', 'Kuala Lumpur']\n",
    "    return random.choice(random_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b769d2-1630-46b1-92bd-8590ac98db41",
   "metadata": {},
   "source": [
    "The function is a tool already (after using decorator). In order to test the tool, call `.run()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6afef075-2d55-42aa-8ba6-3b65899b4a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'For Jakarta temperature: 28.30 and weather: Partly cloudy'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_weather.run('Jakarta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a62892a-6ed3-4a14-b065-8a5c86a9ebd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seoul'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_location.run({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803366c8-18a6-4cf5-95de-f5435840ac48",
   "metadata": {},
   "source": [
    "Use langgraph function to create a react agent (stands for Reasoning and Action agent). On a high level, given a query, the model will [be](https://www.leewayhertz.com/react-agents-vs-function-calling-agents/):\n",
    "1. Break down the task into smaller step, choosing the required tools\n",
    "2. Exceute the step based on the tools\n",
    "3. Observe the result (should it use another tools or return the answer)\n",
    "4. Give response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57d6a2ac-aa3a-4117-b423-96a4df368c80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The temperature in Singapore is 25.40 degrees Celsius and it's partly cloudy.\\n\""
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "# query = \"How's the weather in Jakarta?\"\n",
    "# query = \"What's my current location, and what's the temperature?\"\n",
    "query = \"What's the temperature on my current location?\" # the agent is smart enough to call the get_location tools first, before pass it to the get_weather tools\n",
    "agent_executor = create_react_agent(model=llm, tools=[get_weather, get_current_location])\n",
    "message = agent_executor.invoke({\n",
    "    'messages': [\n",
    "        ('human', query)\n",
    "    ]\n",
    "})\n",
    "message['messages'][-1].content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360b99f-eec1-4979-81fd-5958de141d57",
   "metadata": {},
   "source": [
    "## Saving Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8065f9c-0ead-4125-959a-4ed2dde68c98",
   "metadata": {},
   "source": [
    "Langgraph provides a way to save a chat session by having thread_id. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d10b169-6680-4504-b66e-d59d7c43ac9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "agent_executor = create_react_agent(model=llm, tools=[get_weather, get_weather_average], checkpointer=memory)\n",
    "\n",
    "# create configuration for Thread Id\n",
    "config = {\"configurable\": {\"thread_id\": \"test-thread\"}}\n",
    "message = agent_executor.invoke({\n",
    "    'messages': [\n",
    "        ('human', query)\n",
    "    ]},\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "808ee2a0-09b0-43ea-8dc8-230b3f468dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The temperature in Seoul is -9.8°C and the weather is clear.  In Tokyo it is 3.3°C and partly cloudy. Jakarta is 28.1°C and partly cloudy, while Kuala Lumpur is 26.2°C and partly cloudy.\\n\\nThe average temperature across all four cities is 11.95°C.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-2e08119f-4285-4ff7-8525-ea71a12fdde5-0', usage_metadata={'input_tokens': 234, 'output_tokens': 79, 'total_tokens': 313, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa829bbc-a233-4346-a41b-87e0dbf48eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = agent_executor.invoke({\n",
    "    'messages': [\n",
    "        ('human', 'What is the city that I ask previously?')\n",
    "    ]},\n",
    "    config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d697209c-5609-4c5e-97c7-da39c233f19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The cities you asked about previously were Seoul, Tokyo, Jakarta, and Kuala Lumpur.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-a2f664c6-b669-45b4-8144-3b1e43cab23d-0', usage_metadata={'input_tokens': 322, 'output_tokens': 18, 'total_tokens': 340, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m['messages'][-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
