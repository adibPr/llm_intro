{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "102ff4b4-2396-483d-bae5-7af3d833c102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/D/miniconda/envs/llm_intro/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a419f1-ac64-4747-86d9-8b4016104a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure GOOGLE_API_KEY (or any other llm provider, must exactly the same)\n",
    "_ = load_dotenv(find_dotenv())\n",
    "# or put it into variable and pass it to llm model \n",
    "# google_api_key = os.getenv('GOOGLE_API_KEY') # pass this to the model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ef716-c12a-45df-b0fc-db476f0bac66",
   "metadata": {},
   "source": [
    "# Multiple Ways of Query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95d0e9-443c-4a0d-b558-438ccedfb785",
   "metadata": {},
   "source": [
    "**Simple Invoke**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67bc93ff-b3ac-4d98-8b55-4daaefa92990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# available model in: https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "response = llm.invoke(\"What is the good thing we can do to try LLM?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a01978d-f17d-4897-9eb8-7492a74ff61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8bec70a-6e41-49e9-a010-a05a03e0a711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are many good things you can do to try out LLMs (Large Language Models)!  It depends on your goals and interests, but here are a few ideas categorized by approach:\n",
      "\n",
      "**For Exploration and Learning:**\n",
      "\n",
      "* **Experiment with different prompts:**  Try asking open-ended questions, specific factual queries, creative writing prompts (poems, stories, scripts), code generation requests, translation tasks, and summarization tasks.  See how the LLM responds and how it handles different styles of input.\n",
      "* **Compare different LLMs:** Many LLMs are publicly available (e.g., through APIs or web interfaces).  Try the same prompt on several different models and compare their outputs in terms of accuracy, creativity, and style.  This helps you understand the strengths and weaknesses of each model.\n",
      "* **Use a playground environment:** Many providers offer interactive playgrounds where you can experiment with parameters and settings to fine-tune the LLM's behavior.  This is a great way to learn about how these models work under the hood.\n",
      "* **Follow tutorials and documentation:**  The documentation for many LLMs provides examples and tutorials that can guide you through different use cases.\n",
      "\n",
      "**For Practical Application:**\n",
      "\n",
      "* **Automate repetitive tasks:** Use an LLM to generate drafts of emails, reports, or other documents.  This can save you time and effort.\n",
      "* **Improve your writing:** Use an LLM to help you brainstorm ideas, refine your writing style, or check for grammar and spelling errors.\n",
      "* **Learn a new skill:**  Use an LLM to translate text, generate code snippets, or explain complex concepts.  This can be a valuable tool for self-learning.\n",
      "* **Build a simple application:**  Integrate an LLM into a small project, such as a chatbot or a question-answering system. This will give you hands-on experience with using LLMs in a real-world context.\n",
      "* **Explore creative applications:** Use LLMs for creative writing, music generation, or image captioning.  The possibilities are endless!\n",
      "\n",
      "\n",
      "**Important Considerations:**\n",
      "\n",
      "* **Be aware of limitations:** LLMs are not perfect. They can sometimes generate inaccurate, nonsensical, or biased output.  Always critically evaluate the information they provide.\n",
      "* **Be mindful of ethical implications:**  Consider the potential societal impact of your use of LLMs. Avoid using them for malicious purposes, such as generating harmful content or spreading misinformation.\n",
      "* **Start small and iterate:** Don't try to do too much at once. Start with a simple task and gradually increase the complexity as you gain experience.\n",
      "\n",
      "\n",
      "By following these suggestions, you can effectively explore the capabilities of LLMs and find ways to use them productively and responsibly.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853f3882-c4ee-4d84-a1bb-19121d3712a1",
   "metadata": {},
   "source": [
    "**Using Template**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed6e07f1-ea70-42bb-b4bf-5a6b20d5c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMs offer a wide range of potential benefits across many sectors.  Here are some good things we can do with them:\n",
      "\n",
      "**Improving Productivity and Efficiency:**\n",
      "\n",
      "* **Automation of tasks:** LLMs can automate repetitive tasks like writing emails, summarizing documents, generating reports, and translating languages, freeing up human workers for more complex and creative endeavors.\n",
      "* **Enhanced research:** LLMs can quickly sift through vast amounts of data to identify relevant information, accelerating research in various fields like medicine, science, and engineering.\n",
      "* **Improved customer service:** LLMs power chatbots and virtual assistants that provide 24/7 customer support, answering questions and resolving issues efficiently.\n",
      "\n",
      "**Enhancing Creativity and Innovation:**\n",
      "\n",
      "* **Content creation:** LLMs can assist in writing novels, poems, scripts, articles, and marketing copy, offering new creative possibilities for writers and artists.\n",
      "* **Idea generation:** They can help brainstorm ideas for products, services, and solutions, sparking innovation in various industries.\n",
      "* **Personalized learning:** LLMs can tailor educational materials to individual student needs, creating more engaging and effective learning experiences.\n",
      "\n",
      "**Solving Complex Problems:**\n",
      "\n",
      "* **Data analysis and interpretation:** LLMs can analyze complex datasets and extract meaningful insights, helping businesses and researchers make better decisions.\n",
      "* **Scientific discovery:** They can assist in modeling complex systems and predicting outcomes, accelerating progress in fields like drug discovery and climate modeling.\n",
      "* **Healthcare improvements:** LLMs can assist in diagnosing diseases, personalizing treatment plans, and providing patients with better information and support.\n",
      "\n",
      "\n",
      "**Accessibility and Inclusivity:**\n",
      "\n",
      "* **Language translation:**  Breaking down communication barriers across languages and cultures.\n",
      "* **Accessibility for people with disabilities:**  Providing alternative ways to interact with technology and access information.\n",
      "* **Education for underserved communities:** Providing access to high-quality educational resources in areas with limited access to traditional schooling.\n",
      "\n",
      "\n",
      "It's important to note that while LLMs offer great potential, it's crucial to address ethical concerns surrounding bias, misinformation, and job displacement.  Responsible development and deployment are essential to maximizing the benefits and mitigating the risks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "template = \"\"\"\n",
    "What is the good thing we can do with LLM?\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template)\n",
    "print(prompt.pipe(llm).invoke({}).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf6803f-717b-4024-8d37-749d193a91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLMs can automate tasks, improve accessibility (e.g., translation), personalize education, and accelerate scientific discovery by rapidly processing and analyzing vast amounts of information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using template usually for passing arguments\n",
    "template = \"\"\"\n",
    "What is the good thing we can do with LLM? Write in less than {max_words} words.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=['max_words'])\n",
    "print(prompt.pipe(llm).invoke({'max_words': 50}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d470473-98ae-462c-ac19-c157de964fdd",
   "metadata": {},
   "source": [
    "**Using Roles**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf26c8c-da49-443a-a32c-26f902407da5",
   "metadata": {},
   "source": [
    "Three distinct roles for LangChain:\n",
    "* System: for initial instruction\n",
    "* Human: the actual prompt/message from us, user/human\n",
    "* AI: the response from the LLM\n",
    "\n",
    "Slightly different wording from OpenAI with System, User and Assistant, but the usage are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f80b85-b96c-4abf-9585-a85579e2dcd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try a tomato and mozzarella sandwich!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "chats = (\n",
    "    [\n",
    "        SystemMessage(content=\"\"\"\n",
    "            You are a nice AI bot that helps a user figure out what to eat in one short sentence. \n",
    "            You can only response to question regarding food. \n",
    "            Any other question that are asked not related to food will be answerd with \"I don't know\" \n",
    "            \"\"\"),\n",
    "        HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
    "    ]\n",
    ")\n",
    "print(llm.invoke(chats).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4e23f84-1969-45e8-bc1b-7ff99744ac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chats = (\n",
    "    [\n",
    "        SystemMessage(content=\"\"\"\n",
    "            You are a nice AI bot that helps a user figure out what to eat in one short sentence. \n",
    "            You can only response to question regarding food. \n",
    "            Any other question that are asked not related to food will be answerd with \"I don't know\" \n",
    "            \"\"\"),\n",
    "        HumanMessage(content=\"Who are the winner of 2024 world cup?\")\n",
    "    ]\n",
    ")\n",
    "print(llm.invoke(chats).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9632476-ab3c-4380-991b-0aa7e9540bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=llm.invoke(chats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a8bc534-da44-4685-a3d7-d2dac5106fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Who are the inventor of transformer architecture?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transformer architecture was invented by researchers at Google in 2017.  The key paper, \"Attention is All You Need,\" lists Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin as authors.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Explain it to me like I'm 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagine you have a big box of LEGOs, and you want to build a really cool castle.  Normally, you'd build it piece by piece, in order.\n",
      "\n",
      "A regular computer program for understanding language is a bit like that: it looks at each word one at a time.\n",
      "\n",
      "But the Transformer is different! It's like having a bunch of tiny helpers who all look at *all* the LEGOs at the same time.  They each whisper to each other about which LEGOs are important for building the castle –  \"That pointy one is a good tower piece!\", \"Those bricks go together to make a wall!\"\n",
      "\n",
      "Then, they all work together to build the castle quickly and cleverly, understanding how all the pieces relate to each other, even if they're far apart.  That's what \"attention\" means – paying attention to all the important parts at once, not just one by one.  It makes building the castle (understanding language) much faster and better!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  can fish fly?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have the context to answer questions outside of artificial intelligence.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  break\n"
     ]
    }
   ],
   "source": [
    "history = [\n",
    "    SystemMessage(content=\"\"\"\n",
    "        You are a bot that will help a user to answer their question regarding AI. \n",
    "        Any other questions that are not part of AI, simply answer that you don't have the context for it\n",
    "    \"\"\")\n",
    "]\n",
    "\n",
    "while True:\n",
    "    next_sent = input(\">> \")\n",
    "    if next_sent == \"break\":\n",
    "        break\n",
    "    history.append(HumanMessage(content=next_sent))\n",
    "    response = llm.invoke(history)\n",
    "    print(response.content)\n",
    "    history.append(response)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "862bb31e-580d-4acb-a8f6-6ddc915d7ef6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system -- \n",
      "        You are a bot that will help a user to answer their question regarding AI. \n",
      "        Any oth\n",
      "human -- Who are the inventor of transformer architecture?\n",
      "ai -- The Transformer architecture was invented by researchers at Google in 2017.  The key paper, \"Attenti\n",
      "human -- Explain it to me like I'm 5\n",
      "ai -- Imagine you have a big box of LEGOs, and you want to build a really cool castle.  Normally, you'd bu\n",
      "human -- can fish fly?\n",
      "ai -- I don't have the context to answer questions outside of artificial intelligence.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for h in history:\n",
    "    print(h.type + \" -- \" + h.content[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695b6f03-9260-4c24-8309-568efa1fd3fa",
   "metadata": {},
   "source": [
    "**Template when using Chat Roles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8d001d2-10fa-403f-84c6-a60eaff37ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  Who are the founder of machine learning?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tidak ada satu penemu tunggal pembelajaran mesin.  Ia berkembang dari berbagai kontribusi ilmuwan komputer dan matematikawan selama beberapa dekade.  Arthur Samuel sering disebut sebagai pelopor awal.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  With 100 words or more, describe the difference between machine learning and deep learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pembelajaran mesin (ML) adalah subset dari kecerdasan buatan (AI) yang memungkinkan sistem komputer untuk belajar dari data tanpa diprogram secara eksplisit.  ML menggunakan algoritma untuk mengidentifikasi pola, membuat prediksi, dan meningkatkan kinerjanya dari waktu ke waktu.  Algoritma ML meliputi regresi, klasifikasi, dan pengelompokan.\n",
      "\n",
      "Pembelajaran mendalam (DL), di sisi lain, adalah subset dari ML yang menggunakan jaringan saraf tiruan (ANN) dengan banyak lapisan (lapisan tersembunyi) untuk mengekstrak fitur tingkat tinggi dari data.  DL memerlukan data dalam jumlah besar untuk pelatihan yang efektif dan mampu menangani data kompleks seperti gambar, suara, dan teks.  DL unggul dalam tugas-tugas seperti pengenalan gambar dan pemrosesan bahasa alami, di mana ML tradisional mungkin kurang efektif.  Singkatnya, DL adalah pendekatan ML yang lebih canggih dan kompleks.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  From your system, how many words are allowed?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saya diprogram untuk membatasi jawaban saya hingga maksimal 50 kata dalam Bahasa Indonesia.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  And why you write 100 words for my previous question?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maaf, saya mengalami kesalahan dalam mengikuti batasan kata pada jawaban sebelumnya.  Saya masih dalam pengembangan dan belajar untuk selalu mematuhi batasan yang telah ditetapkan.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      ">>  break\n"
     ]
    }
   ],
   "source": [
    "# see: https://python.langchain.com/docs/concepts/prompt_templates/\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# the format is different, with system, user, and assistants category inside a tuple\n",
    "\n",
    "MAX_WORD=50\n",
    "LANGUAGE='Bahasa'\n",
    "\n",
    "history = [\n",
    "    (\"system\", \"\"\"\n",
    "        You are a bot that will help a user to answer their question regarding AI. \n",
    "        Any other questions that are not part of AI, simply answer that you don't have the context for it.\n",
    "        You only need to answer at most {max_word} words and use the language of {language}\n",
    "    \"\"\"\n",
    "    )\n",
    "]\n",
    "\n",
    "history = ChatPromptTemplate(history).invoke({'max_word': MAX_WORD, 'language': LANGUAGE}).messages\n",
    "\n",
    "while True:\n",
    "    next_sent = input(\">> \")\n",
    "    if next_sent == \"break\":\n",
    "        break\n",
    "    history.append(HumanMessage(content=next_sent))\n",
    "    \n",
    "    response = llm.invoke(history)\n",
    "    print(response.content)\n",
    "    history.append(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d266c-168a-419b-8cff-c9a1f978dc8e",
   "metadata": {},
   "source": [
    "**Structured Output**\n",
    "\n",
    "See: https://python.langchain.com/docs/how_to/structured_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed8d55c6-2acb-4efa-a212-9f1db9402cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95ccbec8-2892-4288-9fe9-4d020b149c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Country(BaseModel):\n",
    "    name: str = Field(description='The country name')\n",
    "    capital: str = Field(description='The capital country')\n",
    "    income_per_capita_usd: int = Field(description='The income per capita in USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f87f3a66-7ffe-4ef3-a256-c204c99a131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_structured = llm.with_structured_output(Country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39fa2448-880f-4cb3-94db-f35d803110c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Country(name='Indonesia', capital='Jakarta', income_per_capita_usd=4300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_structured.invoke(\"Described Indonesia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83360eb6-e6e1-4cb4-8d9c-0bb0cda484bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
